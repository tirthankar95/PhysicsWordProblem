{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\wsl.localhost\\Ubuntu-24.04\\home\\tirthankar-mittra\\PhysicsWordProblem\\NOVELTY_SCORE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "%cd /home/tirthankar-mittra/PhysicsWordProblem/NOVELTY_SCORE/\n",
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from collections import defaultdict\n",
    "import math \n",
    "\n",
    "def bleu_score(s_ref, s, upper_limit = 5, REF = 40):\n",
    "  s_ref_list = [word.lower() for word in s_ref.split()]\n",
    "  s_list = [word.lower() for word in s.split()]\n",
    "  def ngram(sentence, gram):\n",
    "    n = len(sentence)\n",
    "    n_gram_dict = defaultdict(int)\n",
    "    for idx in range(n - gram + 1):\n",
    "       n_gram_dict[\" \".join(sentence[idx:idx + gram])] += 1\n",
    "    return n_gram_dict\n",
    "  score = 0.0\n",
    "  for gram in range(2, upper_limit + 1):\n",
    "    n_gram_score = 0\n",
    "    s_ref_ngram = ngram(s_ref_list, gram)\n",
    "    s_ngram = ngram(s_list, gram)\n",
    "    for phrase in s_ngram:\n",
    "      if phrase in s_ref_ngram:\n",
    "        n_gram_score += min(s_ref_ngram[phrase], s_ngram[phrase])\n",
    "    score += math.log((1 + n_gram_score) / (1 + len(s_ngram)))\n",
    "  c1, c2 = len(s_ref_list), len(s_list)\n",
    "  cavg = (c1 + c2) // 2\n",
    "  bp = min(1, math.exp(1 - REF/cavg))\n",
    "  return round(bp * math.exp(score), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(filename):\n",
    "    question_arr = []\n",
    "    with open(f\"{filename}\", \"r\") as file:\n",
    "        question = \"\"\n",
    "        pattern = r\"\\b\\d+(\\.\\d+)?([eE][+-]?\\d+)?\\b\"\n",
    "        stop_signs = ['.', ',', '?', '!', ':', ';', '(', ')', '[', ']', '{', '}', '<', '>', '\\\\', '|', '`', '~', '@', '#', '$', '%', '&', '*', '-', '_', '+', '=', '\"', \"'\"]   \n",
    "        for line in file:\n",
    "            for ch in line:\n",
    "                if ch == '{': \n",
    "                    question = \"\" \n",
    "                elif ch == '}':\n",
    "                    question_arr.append(question)\n",
    "                else:  question += ch\n",
    "        for idx, question in enumerate(question_arr):\n",
    "            question_arr_temp = []\n",
    "            question = question.strip()\n",
    "            for stop_sign in stop_signs:\n",
    "                question = question.replace(stop_sign, \"\")\n",
    "            question = re.sub(pattern, \"X\", question)\n",
    "            for word in question.split():\n",
    "                question_arr_temp.append(word.lower())\n",
    "            question_arr[idx] = \" \".join(question_arr_temp)\n",
    "    return question_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conformity Score[own]:        0.0914\n",
      "Conformity Score[deepseek]:   0.2442\n",
      "Conformity Score[mistral]:    1.0336\n",
      "Conformity Score[llama]:      0.4539\n",
      "Conformity Score[gpt3.5turbo]:0.1206\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"own\", \"deepseek\", \"mistral\", \"llama\", \"gpt3.5turbo\"]\n",
    "first_col_size = 30\n",
    "for model_name in model_names:\n",
    "    qarr = parse_data(f\"{model_name}.dat\")\n",
    "    total_bs, qn = 0, len(qarr)\n",
    "    for i in range(qn):\n",
    "        for j in range(i+1, qn):\n",
    "            total_bs += bleu_score(qarr[i], qarr[j])\n",
    "    prefix = f'Conformity Score[{model_name}]:'\n",
    "    print(f'{prefix}' + ' ' * (first_col_size - len(prefix)) +\\\n",
    "          f'{round(total_bs, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
